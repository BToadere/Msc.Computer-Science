{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar datos (asumiendo CSV, si el formato es diferente avísame)\n",
    "df = pd.read_csv(\"../0.data/casas.trn.txt\", sep='\\s+' , header=None)\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = df.iloc[:, :-1].values  # Todas las columnas menos la última\n",
    "y = df.iloc[:, -1].values   # Última columna (precio de la vivienda)\n",
    "\n",
    "# Normalizar los datos (media 0, varianza 1)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento (70%), validación (15%) y prueba (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  # Importamos el módulo de redes neuronales de PyTorch\n",
    "\n",
    "# Definimos la clase del perceptrón, heredando de nn.Module\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        Constructor del perceptrón.\n",
    "        \n",
    "        Parámetros:\n",
    "        - input_size: Número de entradas (cantidad de características de cada muestra).\n",
    "        - hidden_size: Número de neuronas en la capa oculta.\n",
    "        \"\"\"\n",
    "        super(Perceptron, self).__init__()  # Inicializa nn.Module para registrar parámetros\n",
    "        \n",
    "        # Definimos la capa oculta (fully connected)\n",
    "        self.hidden = nn.Linear(input_size, hidden_size)  \n",
    "        self.f_hidden = nn.Tanh()\n",
    "\n",
    "        # Definimos la capa de salida con 1 neurona (para regresión)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        # Esto es la función identidad, realmente no haria falta ponerla\n",
    "        # en forward simplemnte no le aplicamos ninguna función solo la capa\n",
    "        self.f_output = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define el flujo de datos a través de la red neuronal.\n",
    "        \n",
    "        Parámetro:\n",
    "        - x: Tensor de entrada (muestra o batch de datos)\n",
    "        \n",
    "        Retorna:\n",
    "        - La predicción del modelo (salida de la capa final)\n",
    "        \"\"\"\n",
    "        x = self.f_hidden(self.hidden(x))  # Aplicamos la capa oculta + activación Tanh\n",
    "        x = self.f_output(self.output(x))  # Aplicamos la capa de salida sin activación\n",
    "        return x  # Devolvemos la salida final del modelo\n",
    "\n",
    "# Crear el modelo con los tamaños adecuados\n",
    "input_size = X.shape[1]  # Número de características de entrada (columnas del dataset)\n",
    "hidden_size = 3  # Número de neuronas en la capa oculta (valor arbitrario)\n",
    "\n",
    "model = Perceptron(input_size, hidden_size)  # Instanciamos el modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Argumento para saer en que estado esta el modelo train o eval\n",
    "model.training\n",
    "# model.eval()\n",
    "# model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()  # Error cuadrático medio\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002)  # Descenso de gradiente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0, Pérdida: 17.8371\n",
      "Época 100, Pérdida: 16.2624\n",
      "Época 200, Pérdida: 14.9660\n",
      "Época 300, Pérdida: 13.9790\n",
      "Época 400, Pérdida: 13.2646\n",
      "Época 500, Pérdida: 12.7349\n",
      "Época 600, Pérdida: 12.3298\n",
      "Época 700, Pérdida: 12.0092\n",
      "Época 800, Pérdida: 11.7488\n",
      "Época 900, Pérdida: 11.5331\n",
      "Época 1000, Pérdida: 11.3519\n",
      "Época 1100, Pérdida: 11.1976\n",
      "Época 1200, Pérdida: 11.0644\n",
      "Época 1300, Pérdida: 10.9480\n",
      "Época 1400, Pérdida: 10.8451\n",
      "Época 1500, Pérdida: 10.7532\n",
      "Época 1600, Pérdida: 10.6705\n",
      "Época 1700, Pérdida: 10.5955\n",
      "Época 1800, Pérdida: 10.5271\n",
      "Época 1900, Pérdida: 10.4644\n",
      "Época 2000, Pérdida: 10.4069\n",
      "Época 2100, Pérdida: 10.3538\n",
      "Época 2200, Pérdida: 10.3048\n",
      "Época 2300, Pérdida: 10.2595\n",
      "Época 2400, Pérdida: 10.2174\n",
      "Época 2500, Pérdida: 10.1784\n",
      "Época 2600, Pérdida: 10.1420\n",
      "Época 2700, Pérdida: 10.1081\n",
      "Época 2800, Pérdida: 10.0765\n",
      "Época 2900, Pérdida: 10.0469\n",
      "Época 3000, Pérdida: 10.0191\n",
      "Época 3100, Pérdida: 9.9931\n",
      "Época 3200, Pérdida: 9.9687\n",
      "Época 3300, Pérdida: 9.9458\n",
      "Época 3400, Pérdida: 9.9242\n",
      "Época 3500, Pérdida: 9.9038\n",
      "Época 3600, Pérdida: 9.8846\n",
      "Época 3700, Pérdida: 9.8664\n",
      "Época 3800, Pérdida: 9.8493\n",
      "Época 3900, Pérdida: 9.8330\n",
      "Época 4000, Pérdida: 9.8176\n",
      "Época 4100, Pérdida: 9.8029\n",
      "Época 4200, Pérdida: 9.7889\n",
      "Época 4300, Pérdida: 9.7757\n",
      "Época 4400, Pérdida: 9.7630\n",
      "Época 4500, Pérdida: 9.7509\n",
      "Época 4600, Pérdida: 9.7393\n",
      "Época 4700, Pérdida: 9.7281\n",
      "Época 4800, Pérdida: 9.7175\n",
      "Época 4900, Pérdida: 9.7072\n",
      "Época 5000, Pérdida: 9.6974\n",
      "Época 5100, Pérdida: 9.6879\n",
      "Época 5200, Pérdida: 9.6787\n",
      "Época 5300, Pérdida: 9.6698\n",
      "Época 5400, Pérdida: 9.6612\n",
      "Época 5500, Pérdida: 9.6529\n",
      "Época 5600, Pérdida: 9.6449\n",
      "Época 5700, Pérdida: 9.6370\n",
      "Época 5800, Pérdida: 9.6294\n",
      "Época 5900, Pérdida: 9.6220\n",
      "Época 6000, Pérdida: 9.6147\n",
      "Época 6100, Pérdida: 9.6077\n",
      "Época 6200, Pérdida: 9.6007\n",
      "Época 6300, Pérdida: 9.5940\n",
      "Época 6400, Pérdida: 9.5873\n",
      "Época 6500, Pérdida: 9.5808\n",
      "Época 6600, Pérdida: 9.5744\n",
      "Época 6700, Pérdida: 9.5680\n",
      "Época 6800, Pérdida: 9.5618\n",
      "Época 6900, Pérdida: 9.5556\n",
      "Época 7000, Pérdida: 9.5496\n",
      "Época 7100, Pérdida: 9.5435\n",
      "Época 7200, Pérdida: 9.5375\n",
      "Época 7300, Pérdida: 9.5316\n",
      "Época 7400, Pérdida: 9.5257\n",
      "Época 7500, Pérdida: 9.5198\n",
      "Época 7600, Pérdida: 9.5139\n",
      "Época 7700, Pérdida: 9.5080\n",
      "Época 7800, Pérdida: 9.5022\n",
      "Época 7900, Pérdida: 9.4963\n",
      "Época 8000, Pérdida: 9.4904\n",
      "Época 8100, Pérdida: 9.4845\n",
      "Época 8200, Pérdida: 9.4785\n",
      "Época 8300, Pérdida: 9.4725\n",
      "Época 8400, Pérdida: 9.4665\n",
      "Época 8500, Pérdida: 9.4604\n",
      "Época 8600, Pérdida: 9.4542\n",
      "Época 8700, Pérdida: 9.4479\n",
      "Época 8800, Pérdida: 9.4416\n",
      "Época 8900, Pérdida: 9.4351\n",
      "Época 9000, Pérdida: 9.4286\n",
      "Época 9100, Pérdida: 9.4220\n",
      "Época 9200, Pérdida: 9.4152\n",
      "Época 9300, Pérdida: 9.4083\n",
      "Época 9400, Pérdida: 9.4013\n",
      "Época 9500, Pérdida: 9.3941\n",
      "Época 9600, Pérdida: 9.3868\n",
      "Época 9700, Pérdida: 9.3794\n",
      "Época 9800, Pérdida: 9.3718\n",
      "Época 9900, Pérdida: 9.3641\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000  # Número de iteraciones\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Modo entrenamiento\n",
    "    optimizer.zero_grad()  # Resetear gradientes\n",
    "    \n",
    "    output = model(X_train)  # Forward pass\n",
    "    loss = criterion(output, y_train)  # Calcular pérdida\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Actualizar pesos\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Época {epoch}, Pérdida: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio en test: 510.6031\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Cambiar a modo evaluación\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "\n",
    "print(f\"Error cuadrático medio en test: {test_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redespytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
